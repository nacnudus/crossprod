+++
date = "2014-11-30T17:30:00"
math = true
title = "Painfully big data in a restrictive IT environment"
abstract = "Tips and tricks for handling bigger-than-memory data"
abstract_short = "Tips and tricks for handling bigger-than-memory data"
event = "WRUG: The Wellington R Usergroup"
event_url = "http://edinbr.org/edinbr/2016/10/15/Oct-meeting.html"
location = "Wellington, New Zealand"
selected = false
url_pdf = ""
url_slides = ""
url_video = "https://www.youtube.com/watch?v=4f64ICIbDO8"
+++

Does your IT department provide 16GB of RAM? Does it allow uploading of data to
a high-performance cloud computing service? Oh really? In this talk, I present
some coping strategies for legacy hardware using packages like

* [data.table](https://github.com/Rdatatable/data.table/wiki)
* [dplyr](https://github.com/hadley/dplyr)
* [ff](https://cran.r-project.org/web/packages/ff/index.html)
* [ff-base](https://cran.r-project.org/web/packages/ffbase/index.html)
* [LaF](https://cran.r-project.org/web/packages/LaF/index.html)
* [MonetDB](https://github.com/hannesmuehleisen/MonetDBLite)
* [spatialite](https://www.gaia-gis.it/fossil/libspatialite/index)
